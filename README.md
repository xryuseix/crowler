# ğŸ¦â€â¬› Crowler

**_A Generic Docker-based Web Crawler that can be used to crawl any website and extract data from it._**

## How to use

### 1. Edit the `config.yaml` file

[config.yaml](./app/config.yaml) is the configuration file for the crawler.

example:

```yaml
# åŒæ™‚ã«å–å¾—ã™ã‚‹Workerã®è¨­å®š
thread_max: 3

# æ¬¡ã®ã‚¯ãƒ­ãƒ¼ãƒ«ã¾ã§ã®å¾…ã¡æ™‚é–“ã®è¨­å®š
wait_time: 0.5

# é–‹ã‹ãªã„ã‚µã‚¤ãƒˆã®è¨­å®š
## same-url...åŒã˜URLã¯äºŒåº¦ã¨é–‹ã‹ãªã„
## same-domain...åŒã˜ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã‚µã‚¤ãƒˆã¯äºŒåº¦ã¨é–‹ã‹ãªã„
## none...é–‹ã‹ãªã„ã‚µã‚¤ãƒˆã®è¨­å®šã‚’ã—ãªã„
duplicate: same-domain

# å–å¾—ã™ã‚‹å†…å®¹ã®è¨­å®š
fetch_contents:
  html: true
  screenshot: true
  css_js_other: true

# åˆæœŸãƒ‡ãƒ¼ã‚¿ã®è¨­å®š
seed_file: seed.txt
random_seed: false

# å‡ºåŠ›å…ˆã®è¨­å®š
output_dir: out

# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®è¨­å®š
timeout:
  # ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã«å¯¾ã™ã‚‹ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
  navigate: 30
  # ãƒšãƒ¼ã‚¸å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ã«å¯¾ã™ã‚‹ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
  fetch: 5

# seedãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¹…å„ªå…ˆæ¢ç´¢ã§é–²è¦§ã™ã‚‹æ·±ã•ã®æœ€å¤§å€¤
hops: 1
```

### 2. Edit the `seed.txt` file

[seed.txt](./app/seed.txt) is the seed file for the crawler.

example:

```txt
https://www.google.com/search?q=foo
https://search.yahoo.co.jp/search?p=bar
https://search.goo.ne.jp/web.jsp?MT=buz
```

### 3. Run

```bash
docker-compose up
```
