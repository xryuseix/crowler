# ğŸ¦â€â¬› Crowler

**_A Generic Docker-based Web Crawler using chrome-devtools-protocol._**

<div align="center">
  <img src="./demo.gif" alt="Demo" />
</div>

## Output

Related files are also saved so that web pages can be restored.

```txt
out/example.com
â”œâ”€â”€ index.html     // main page of the website(external links are replaced with local links)
â”œâ”€â”€ index.old.html // original main page of the website
â”œâ”€â”€ contents
â”‚Â Â  â”œâ”€â”€ 0fae3c61-a154-4283-9216-fc2f63093f1b // js, css, and other files
â”‚Â Â  â”œâ”€â”€ 2a854bf8-238a-4081-9ed4-98291b2682f6 // js, css, and other files
â”‚Â Â  â”œâ”€â”€ ...
â”œâ”€â”€ screenshot.png // screenshot of the website
â””â”€â”€ url_table.json // external links and their corresponding local links
```

## How to use

### 1. Edit the `config.yaml` file

[config.yaml](./app/config.yaml) is the configuration file for the crawler.

example:

```yaml
# åŒæ™‚ã«å–å¾—ã™ã‚‹Workerã®è¨­å®š
# -1ã«ã™ã‚‹ã¨runtime.NumCPU()ã®å€¤ãŒè¨­å®šã•ã‚Œã‚‹
thread_max: -1

# æ¬¡ã®ã‚¯ãƒ­ãƒ¼ãƒ«ã¾ã§ã®å¾…ã¡æ™‚é–“ã®è¨­å®š
wait_time: 0.5

# é–‹ã‹ãªã„ã‚µã‚¤ãƒˆã®è¨­å®š
## same-url...åŒã˜URLã¯äºŒåº¦ã¨é–‹ã‹ãªã„
## same-domain...åŒã˜ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã‚µã‚¤ãƒˆã¯äºŒåº¦ã¨é–‹ã‹ãªã„
## none...é–‹ã‹ãªã„ã‚µã‚¤ãƒˆã®è¨­å®šã‚’ã—ãªã„
duplicate: same-domain

# å–å¾—ã™ã‚‹å†…å®¹ã®è¨­å®š
fetch_contents:
  html: true
  screenshot: true
  css_js_other: true

# åˆæœŸãƒ‡ãƒ¼ã‚¿ã®è¨­å®š
seed_file: seed.txt
random_seed: false

# å‡ºåŠ›å…ˆã®è¨­å®š
output_dir: out

# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®è¨­å®š
timeout:
  # ãƒšãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿ã«å¯¾ã™ã‚‹ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
  navigate: 30
  # ãƒšãƒ¼ã‚¸å†…ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—ã«å¯¾ã™ã‚‹ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
  fetch: 5

# seedãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¹…å„ªå…ˆæ¢ç´¢ã§é–²è¦§ã™ã‚‹æ·±ã•ã®æœ€å¤§å€¤
hops: 1
```

### 2. Edit the `seed.txt` file

[seed.txt](./app/seed.txt) is the seed file for the crawler.

example:

```txt
https://www.google.com/search?q=foo
https://search.yahoo.co.jp/search?p=bar
https://search.goo.ne.jp/web.jsp?MT=buz
```

### 3. Run

```bash
docker-compose up -d
```
